{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook I will try to repair hyperex amplicon extraction tool\n",
    "\n",
    "hyperex keeps crushing when there is forward primer found upstream revese primer:\n",
    "\n",
    "thread 'main' panicked at /home/mg/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/hyperex-0.1.1/src/utils.rs:420:45: slice index starts at 256 but ends at 65 note: run with \\`RUST_BACKTRACE=1` environment variable to display a backtrace Aborted (core dumped)   \n",
    "\n",
    "I will  load the fasta seq with Biopython and then use hyperex on each read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "fasta_seq = list(SeqIO.parse(\"datasets/uchime_reference_dataset_16_10_2022/2022_10_26_chimera_reference_release/untrimmed_sequences/uchime_reference_dataset_untrimmed_16_10_2022.fasta\", \"fasta\"))\n",
    "#fasta_seq = fasta_seq[:300]\n",
    "print((fasta_seq[:5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "primers_df = pd.read_excel(\"my_data/primers.xlsx\",header=1)\n",
    "primers_df[\"better_names\"] = primers_df[\"homogenized primer names\"].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\-\\.\\_]', '_', str(x).replace(\"/\",\"___\")))\n",
    "primers_df_filtered = primers_df[~primers_df[\"primers sequences\"].str.contains(\"[\\\\(a-z\\\\+]\")]\n",
    "primers_df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "Seq(\"GCTGCGTTCTTCATCGATGC\").reverse_complement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.hyperex_repaired import hyperex_repaired"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST hyperex_repaired function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test hyperex_repaired on test_hyperex_repaired.fa\n",
    "test_fasta_seq = list(SeqIO.parse(\"scripts/test_hyperex_repaired.fa\", \"fasta\"))\n",
    "test_res_seq = hyperex_repaired(test_fasta_seq,\"TCCGTAGGTGAACCTGCGG\",\"GCTGCGTTCTTCATCGATGC\")\n",
    "print(\"All  reads:\\n\",\", \".join([i.id for i in test_fasta_seq]),sep=\"\")\n",
    "print(\"Good reads:\\n\",\", \".join([i.id for i in test_res_seq]),sep=\"\")\n",
    "print(\"Bad reads:\\n\",\", \".join(set([i.id for i in test_fasta_seq])-set([i.id for i in test_res_seq])),sep=\"\")\n",
    "test_res_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract amplicons with hyperex repaired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import sys\n",
    "\n",
    "lenky = {}\n",
    "seqs_list = []\n",
    "for n,row in primers_df_filtered.iterrows():\n",
    "    _,primer_seq,region,_,better_name, = list(row)\n",
    "    forw = primer_seq.split(\"/\")[0].strip()\n",
    "    rev = primer_seq.split(\"/\")[1].strip()\n",
    "    print(better_name)\n",
    "    res_seq = hyperex_repaired(fasta_seq,forw,rev)\n",
    "    output_file = f\"../datasets/uchime_reference_dataset_16_10_2022/2022_10_26_chimera_reference_release/amplicons_from_primers_hyperex/{better_name}.fasta\"\n",
    "    with open(output_file, \"w\") as handle:\n",
    "        SeqIO.write(res_seq, handle, \"fasta-2line\")\n",
    "    print(n)\n",
    "    lenky[better_name] = len(res_seq)\n",
    "    seqs_list.append(res_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = {}\n",
    "for p,seq in zip(primers_df_filtered[\"better_names\"],seqs_list):\n",
    "    ids[p] = [i.id for i in seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "ids_one_list = chain.from_iterable([v for k, v in ids.items()])\n",
    "from collections import Counter\n",
    "counts = Counter(ids_one_list)\n",
    "len(counts),len(fasta_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut primers with cutadapt - this is useless - I should do it at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "import os\n",
    "from subprocess import run\n",
    "\n",
    "# Function to sanitize sequence IDs and descriptions\n",
    "def sanitize_fasta_records(records):\n",
    "    sanitized_records = []\n",
    "    for record in records:\n",
    "        sanitized_id = ''.join(c if c.isascii() or c in \"-_.\" else \"_\" for c in record.id)\n",
    "        sanitized_description = ''.join(c if c.isascii() or c in \"-_.\" else \"_\" for c in record.description)\n",
    "        sanitized_records.append(SeqRecord(Seq(str(record.seq)), id=sanitized_id, description=sanitized_description))\n",
    "    return sanitized_records\n",
    "\n",
    "# Iterate over each primer and its corresponding file\n",
    "for _, row in primers_df_filtered.iterrows():\n",
    "    primer_name = row[\"better_names\"]\n",
    "    primer_seq = row[\"primers sequences\"]\n",
    "    input_file = f\"../datasets/uchime_reference_dataset_16_10_2022/2022_10_26_chimera_reference_release/amplicons_from_primers_hyperex/{primer_name}.fasta\"\n",
    "    sanitized_file = f\"../datasets/uchime_reference_dataset_16_10_2022/2022_10_26_chimera_reference_release/amplicons_from_primers_hyperex/{primer_name}_sanitized.fasta\"\n",
    "    output_file = f\"../datasets/uchime_reference_dataset_16_10_2022/2022_10_26_chimera_reference_release/amplicons_from_primers_hyperex/{primer_name}_cut.fasta\"\n",
    "    \n",
    "    # Sanitize the input FASTA file\n",
    "    records = list(SeqIO.parse(input_file, \"fasta\"))\n",
    "    sanitized_records = sanitize_fasta_records(records)\n",
    "    with open(sanitized_file, \"w\") as handle:\n",
    "        SeqIO.write(sanitized_records, handle, \"fasta\")\n",
    "    \n",
    "    # Run cutadapt to cut primers\n",
    "    command = [\n",
    "        \"cutadapt\",\n",
    "        \"-g\", primer_seq.split(\"/\")[0].strip(),  # Forward primer\n",
    "        \"-a\", primer_seq.split(\"/\")[1].strip(),  # Reverse primer\n",
    "        \"-o\", output_file,\n",
    "        sanitized_file\n",
    "    ]\n",
    "    result = run(command, capture_output=True, text=True)\n",
    "    \n",
    "    # Print the result for debugging\n",
    "    print(f\"Processed {primer_name}:\")\n",
    "    print(result.stdout)\n",
    "    print(result.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use Simera on fastas from hyperex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipped = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "from time import sleep\n",
    "from subprocess import run\n",
    "import time\n",
    "from subprocess import TimeoutExpired\n",
    "\n",
    "# Function to append \"_1\" to each read name in the FASTA file\n",
    "def append_suffix_to_fasta(input_file, output_file, suffix=\"_1\"):\n",
    "    records = list(SeqIO.parse(input_file, \"fasta\"))\n",
    "    modified_records = []\n",
    "    for record in records:\n",
    "        record.id = f\"{record.id}{suffix}\"\n",
    "        record.description = \"\"  # Clear description to avoid duplication\n",
    "        modified_records.append(record)\n",
    "    with open(output_file, \"w\") as handle:\n",
    "        SeqIO.write(modified_records, handle, \"fasta-2line\")\n",
    "\n",
    "# Iterate over each primer and its corresponding file\n",
    "for numero,row in enumerate(primers_df_filtered.iterrows()):\n",
    "    if numero < 0: continue\n",
    "    \n",
    "    row = row[1]\n",
    "    primer_name = row[\"better_names\"]\n",
    "    primer_seq = row[\"primers sequences\"]\n",
    "    forward_primer = primer_seq.split(\"/\")[0].strip()\n",
    "    reverse_primer = primer_seq.split(\"/\")[1].strip()\n",
    "        # Check if the FASTA file is empty\n",
    "\n",
    "    if primer_name != \"gITS7___ITS4\": print(\"skipping....\") ; continue\n",
    "    print(primer_name)\n",
    "    input_file = f\"datasets/uchime_reference_dataset_16_10_2022/2022_10_26_chimera_reference_release/amplicons_from_primers_hyperex/{primer_name}_sanitized.fasta\"\n",
    "    modified_file = f\"datasets/uchime_reference_dataset_16_10_2022/2022_10_26_chimera_reference_release/amplicons_from_primers_hyperex/{primer_name}_abund.fasta\"\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = f\"datasets/uchime_reference_dataset_16_10_2022/2022_10_26_chimera_reference_release/amplicons_from_primers_simera/{primer_name}/{timestamp}/\"\n",
    "    records = list(SeqIO.parse(input_file, \"fasta\"))\n",
    "    if len(records) < 10:  # If no records are found, continue to the next iteration\n",
    "        print(f\"Skipping {primer_name} as the file is empty.\")\n",
    "        continue\n",
    "    # Append \"_1\" to each read name\n",
    "    append_suffix_to_fasta(input_file,modified_file)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(\"simera!!!\",primer_name,forward_primer,reverse_primer)\n",
    "    # Run Simera\n",
    "    command = [\n",
    "        \"Simera/Simera\",\n",
    "        \"-i\", modified_file,\n",
    "        \"-o\", output_dir,\n",
    "        \"-n\", \"25\",\n",
    "        \"-s\", \"10000\",\n",
    "        \"-l\", \"0.00005\",\n",
    "        \"-c\", \"100000\", # too large values for big fastas (6+Mb) will freeze Simera sometimes ??? dunno why, it fries my pc tho\n",
    "        \"-f\", forward_primer,                      \n",
    "        \"-r\", reverse_primer,\n",
    "        \"-x\"\n",
    "    ] # Simera is stuck when there is too little seqs in the fasta\n",
    "    #result = run(command, capture_output=True, text=True)\n",
    "    try:\n",
    "        result = run(command, capture_output=True, text=True, timeout=240)  # Timeout after 300 seconds\n",
    "    except TimeoutExpired:\n",
    "        print(f\"Simera timed out for {primer_name}. Skipping...\")\n",
    "        skipped.append((numero,primer_name))\n",
    "        continue  # Skip to the next iteration\n",
    " \n",
    "    # Print the result for debugging\n",
    "    print(f\"Processed {primer_name}:\")\n",
    "    #print(result.stdout)\n",
    "    #print(result.stderr)\n",
    "    print(numero+1,\"/\",len(primers_df_filtered))\n",
    "    sleep(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "Seq(\"GTTCAAAGAYTCGATGATTCAC\").reverse_complement()\n",
    "from random import choice\n",
    "ss = \"\".join([choice(\"ACGT\") for i in range(370)])\n",
    "ss\n",
    "#len(\"GTAAAAGTCGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTATTGAAATAAACTTAGGGGTTGTTGCTGGCCTTTCAAGGGCAATTTTGTGCACGCCTCTATCTATTTCCCTTTAACACCCCCATTGTGCATCTTGTGTAGGTTAACGTAAAGTTAATCTATGTTTTTATTTTTATACCTTTGTTTTTGAATGGGAATGTAATTTTTTAAACCCTCAGTAAGCTCTCATTTTGGAGCTGAAAAGGAAATAAATATGTGTACAACTTTCAACAACGGATCTCTTGGCTCTCGCATCGATGAAGAACGCAGCGAAATGCGATAAGTAATGTGAATTGCAGAATTCAGTGAATCATCGAATCTTTGAAC\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old version\n",
    "import os\n",
    "import subprocess\n",
    "import re\n",
    "from collections import Counter\n",
    "import sys\n",
    "\n",
    "results = []  # List to store the content of hyperex_out.fa files\n",
    "warnings = []  # List to store the warnings\n",
    "errors = []  # List to store the errors\n",
    "hyperex_out_fa = f\"hyperex_temp_out.fa\"\n",
    "hyperex_log = f\"hyperex.log\"\n",
    "hyperex_gff = f\"hyperex_temp_out.gff\"\n",
    "\n",
    "# Clean up any existing temporary files\n",
    "if os.path.exists(hyperex_log): os.remove(hyperex_log)\n",
    "if os.path.exists(hyperex_gff): os.remove(hyperex_gff)\n",
    "if os.path.exists(hyperex_out_fa): os.remove(hyperex_out_fa)\n",
    "\n",
    "# Command template for hyperex\n",
    "command = [\"hyperex\", \"-f\", \"GTGARTCATCGARTCTTTG\", \"-r\", \"TCCTCCGCTTATTGATATGC\", \"-p\", \"hyperex_temp_out\"]\n",
    "\n",
    "lenka = len(fasta_seq)\n",
    "for i, record in enumerate(fasta_seq):\n",
    "    if i % 50 == 0: print(f\"{i}/{lenka}\", end=\"\\r\")\n",
    "    if i >0: command = [\"hyperex\", \"-f\", \"GTGARTCATCGARTCTTTG\", \"-r\", \"TCCTCCGCTTATTGATATGC\", \"-p\", \"hyperex_temp_out\",\"--force\"] \n",
    "    # Convert the record to FASTA format string\n",
    "    fasta_data = f\">{record.id}\\n{str(record.seq)}\\n\"\n",
    "    \n",
    "    # Run hyperex with the FASTA data passed via stdin\n",
    "    process = subprocess.Popen(command, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    stdout, stderr = process.communicate(input=fasta_data)\n",
    "    \n",
    "    # Collect warnings and errors\n",
    "    warnings.extend(list(map(lambda x: x.replace(\"\\x1b[0m]\", \"\"), re.findall(\"WARN(.+)\", stdout))))\n",
    "    errors.extend(stderr)\n",
    "    \n",
    "    # Read results if the output file exists\n",
    "    if os.path.exists(hyperex_out_fa):\n",
    "        with open(hyperex_out_fa, \"r\") as fa_file:\n",
    "            results.append(fa_file.read())\n",
    "\n",
    "# Clean up any remaining temporary files\n",
    "if os.path.exists(hyperex_out_fa): os.remove(hyperex_out_fa)\n",
    "if os.path.exists(hyperex_log): os.remove(hyperex_log)\n",
    "if os.path.exists(hyperex_gff): os.remove(hyperex_gff)\n",
    "\n",
    "print()\n",
    "real_results = [i for i in results if len(i) > 0]\n",
    "print(\"number of real results:\", len(real_results))\n",
    "warning_counts = Counter(warnings)\n",
    "error_counts = Counter(errors)\n",
    "print(\"ERRORS:\", error_counts, \"WARNINGS:\", warning_counts, sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old version 2\n",
    "import os\n",
    "import subprocess\n",
    "#from time import sleep\n",
    "#import sys\n",
    "import re\n",
    "from collections import Counter\n",
    "results = []  # List to store the content of hyperex_out.fa files\n",
    "warnings = []  # List to store the warnings\n",
    "errors = []  # List to store the errors\n",
    "hyperex_out_fa = f\"hyperex_temp_out.fa\"\n",
    "hyperex_log = f\"hyperex.log\"\n",
    "hyperex_gff = f\"hyperex_temp_out.gff\"\n",
    "temp_filename = f\"hyperex_temp_res.fasta\"\n",
    "if os.path.exists(hyperex_log): os.remove(hyperex_log)\n",
    "if os.path.exists(hyperex_gff): os.remove(hyperex_gff)\n",
    "if os.path.exists(temp_filename): os.remove(temp_filename)  # Delete the temporary input file\n",
    "\n",
    "with open(temp_filename, \"w\") as temp_fasta:\n",
    "    SeqIO.write(fasta_seq[0], temp_fasta, \"fasta\")\n",
    "command = [\"hyperex\",  \"-f\", \"GTGARTCATCGARTCTTTG\", \"-r\", \"TCCTCCGCTTATTGATATGC\",\"-p\",\"hyperex_temp_out\", temp_filename]\n",
    "result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "warnings.extend(list(map(lambda x: x.replace(\"\\x1b[0m]\",\"\"), re.findall(\"WARN(.+)\",result.stdout))))\n",
    "errors.extend(result.stderr)\n",
    "if os.path.exists(hyperex_out_fa):\n",
    "    with open(hyperex_out_fa, \"r\") as fa_file:\n",
    "        results.append(fa_file.read())\n",
    "#print(result.stdout)\n",
    "#print(result.stderr)\n",
    "lenka = len(fasta_seq)\n",
    "command = [\"hyperex\",  \"-f\", \"GTGARTCATCGARTCTTTG\", \"-r\", \"TCCTCCGCTTATTGATATGC\",\"-p\",\"hyperex_temp_out\", temp_filename,\"--force\"]\n",
    "for i, record in enumerate(fasta_seq[1:]):\n",
    "    #temp_filename = f\"hyperex_temp_res.fasta\"\n",
    "    if i % 50 == 0: print(f\"{i}/{lenka}\",end=\"\\r\")\n",
    "    with open(temp_filename, \"w\") as temp_fasta:\n",
    "        SeqIO.write(record, temp_fasta, \"fasta\")\n",
    "    #if i == 0:command = [\"hyperex\",  \"-f\", \"GTGARTCATCGARTCTTTG\", \"-r\", \"TCCTCCGCTTATTGATATGC\",\"-p\",\"hyperex_temp_out\", temp_filename]\n",
    "    result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    warnings.extend(list(map(lambda x: x.replace(\"\\x1b[0m]\",\"\"), re.findall(\"WARN(.+)\",result.stdout))))\n",
    "    errors.extend(result.stderr)\n",
    "    #if os.path.exists(hyperex_out_fa):\n",
    "    with open(hyperex_out_fa, \"r\") as fa_file:\n",
    "        results.append(fa_file.read())\n",
    "\n",
    "if os.path.exists(hyperex_out_fa):os.remove(hyperex_out_fa)  \n",
    "if os.path.exists(hyperex_log): os.remove(hyperex_log)\n",
    "if os.path.exists(hyperex_gff): os.remove(hyperex_gff)\n",
    "if os.path.exists(temp_filename): os.remove(temp_filename)  # Delete the temporary input file\n",
    "\n",
    "print()\n",
    "real_results = [i for i in results if len(i) >0]\n",
    "print(\"number of real results:\",len(real_results))\n",
    "warning_counts = Counter(warnings)\n",
    "error_counts = Counter(errors)\n",
    "print(\"ERRORS:\",list(error_counts),\"WARNINGS:\",\"\\n\".join(list(warning_counts)),sep=\"\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
